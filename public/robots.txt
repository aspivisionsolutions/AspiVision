# AspiVision Solutions Robots.txt

# Allow all bots by default
User-agent: *
Allow: /

# Sitemaps
Sitemap: https://www.aspivision.in/sitemap.xml

# Prevent access to sensitive areas
Disallow: /admin/
Disallow: /private/
Disallow: /temp/
Disallow: /api/
Disallow: /cgi-bin/
Disallow: /wp-admin/
Disallow: /*.sql$
Disallow: /*.zip$
Disallow: /search?
Disallow: /*?replytocom
Disallow: /*?preview
Disallow: /wp-includes/

# Special rules for specific bots
User-agent: GPTBot
Disallow: /

User-agent: ChatGPT-User
Disallow: /

User-agent: Google-Extended
Disallow: /

# Note: Modern search engines don't need explicit Allow directives for standard public pages
# The following are already allowed by default:
# /about
# /services
# /portfolio
# /contact
# /static/
# /images/
# /assets/
# /*.js
# /*.css
# /*.png
# /*.jpg
# /*.jpeg
# /*.gif
# /*.svg

# Rate limiting - Note: Crawl-delay is not supported by Google, use Search Console instead
# Only Bing and some other crawlers respect this
Crawl-delay: 5 